{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLIkiRMseBLw9zdtqLvArZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#experiment -5\n","# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load a dataset (e.g., Ames Housing instead of Boston, which is deprecated)\n","housing = fetch_openml(name='house_prices', as_frame=True)\n","data = housing.frame\n","\n","# Target variable\n","data = data.dropna(subset=['SalePrice'])  # Drop rows where target is missing\n","data = data.drop(columns=['Id'])  # Drop non-informative columns\n","data['PRICE'] = data['SalePrice']\n","data = data.drop(columns=['SalePrice'])\n","\n","# Drop columns with too many missing values or non-numeric types that can't be encoded easily\n","data = data.dropna(thresh=len(data) * 0.9, axis=1)  # Drop columns with >10% missing\n","data = data.dropna()  # Drop rows with any remaining missing values\n","\n","# Encode categorical variables\n","data = pd.get_dummies(data, drop_first=True)\n","\n","# Split dataset into training and testing sets\n","X = data.drop('PRICE', axis=1)\n","y = data['PRICE']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 1. Linear Regression\n","lr = LinearRegression()\n","lr.fit(X_train, y_train)\n","lr_pred = lr.predict(X_test)\n","\n","# 2. Decision Tree\n","dt = DecisionTreeRegressor(random_state=42)\n","dt.fit(X_train, y_train)\n","dt_pred = dt.predict(X_test)\n","\n","# 3. Random Forest\n","rf = RandomForestRegressor(random_state=42, n_estimators=100)\n","rf.fit(X_train, y_train)\n","rf_pred = rf.predict(X_test)\n","\n","# Evaluation Function\n","def evaluate_model(model_name, y_true, y_pred):\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    r2 = r2_score(y_true, y_pred)\n","    print(f\"{model_name} - RMSE: {rmse:.2f}, R2: {r2:.2f}\")\n","\n","# Evaluate all models\n","evaluate_model(\"Linear Regression\", y_test, lr_pred)\n","evaluate_model(\"Decision Tree\", y_test, dt_pred)\n","evaluate_model(\"Random Forest\", y_test, rf_pred)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dC0q_ytb8Cs","executionInfo":{"status":"ok","timestamp":1744737218606,"user_tz":-330,"elapsed":5556,"user":{"displayName":"MIRUNALINI ARCOT RADHAKRISHNAN ANANTHAKUMAR 11239A058","userId":"05774755811913566106"}},"outputId":"e3ebc2f6-f5ae-45bc-ba55-804601693ef9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression - RMSE: 47195.86, R2: 0.48\n","Decision Tree - RMSE: 34657.66, R2: 0.72\n","Random Forest - RMSE: 26526.61, R2: 0.84\n"]}]}]}